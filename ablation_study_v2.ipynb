{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d1fa1ca4eec84785bc5ed1ea2b12c6d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_642ce2962a824c798649f9741c211665",
              "IPY_MODEL_8424851db51d451b981bce7adea04844",
              "IPY_MODEL_7a298c2789ef45a6a1e8da3e517cfc1c"
            ],
            "layout": "IPY_MODEL_992d2604fdb64a5dbd39ac0210e1bfb8"
          }
        },
        "642ce2962a824c798649f9741c211665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_783a721bb3cd42f39c82914acf05e1b1",
            "placeholder": "​",
            "style": "IPY_MODEL_f6a42519cc2a44a78b6a7a02340938d2",
            "value": "100%"
          }
        },
        "8424851db51d451b981bce7adea04844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f750bdd45778415ca9dff3727cdb7f48",
            "max": 36750,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b762ad75bfa1405cb2fc2bbe0e089ace",
            "value": 36750
          }
        },
        "7a298c2789ef45a6a1e8da3e517cfc1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04884e6f206641a99769dc023668e023",
            "placeholder": "​",
            "style": "IPY_MODEL_edfb3b37cc85481ebddb6d01d48e4557",
            "value": " 36750/36750 [01:01&lt;00:00, 1024.00it/s]"
          }
        },
        "992d2604fdb64a5dbd39ac0210e1bfb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "783a721bb3cd42f39c82914acf05e1b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6a42519cc2a44a78b6a7a02340938d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f750bdd45778415ca9dff3727cdb7f48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b762ad75bfa1405cb2fc2bbe0e089ace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04884e6f206641a99769dc023668e023": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edfb3b37cc85481ebddb6d01d48e4557": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27735d0a59f74b159507f0fd8148fbd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19042770d05547ad961af1a73cbfd6a5",
              "IPY_MODEL_a527b67c478f4b4b9b327990f30a2590",
              "IPY_MODEL_e9f21c05f4f841aca084e29c46802e51"
            ],
            "layout": "IPY_MODEL_c810e589d4f54f6bb4c692552f26d9dc"
          }
        },
        "19042770d05547ad961af1a73cbfd6a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06ba0ea5aa8b4fe586faf8b85515d87e",
            "placeholder": "​",
            "style": "IPY_MODEL_b532917f9e734f6192107a5eb7846b8a",
            "value": "100%"
          }
        },
        "a527b67c478f4b4b9b327990f30a2590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7bd2c228eac6422794dbd89158b1c5b8",
            "max": 15750,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_707f580909104ce5a2da0682a1d3a949",
            "value": 15750
          }
        },
        "e9f21c05f4f841aca084e29c46802e51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6765e38dc1a64470bba4bee9baaeb975",
            "placeholder": "​",
            "style": "IPY_MODEL_9f52ddcbda044562b3eb2531593d829b",
            "value": " 15750/15750 [00:15&lt;00:00, 991.26it/s]"
          }
        },
        "c810e589d4f54f6bb4c692552f26d9dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06ba0ea5aa8b4fe586faf8b85515d87e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b532917f9e734f6192107a5eb7846b8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bd2c228eac6422794dbd89158b1c5b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "707f580909104ce5a2da0682a1d3a949": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6765e38dc1a64470bba4bee9baaeb975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f52ddcbda044562b3eb2531593d829b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathusalini/amc-multimodal-ablation/blob/main/ablation_study_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ablation Study: Multi-Modal Fusion for Automatic Modulation Classification\n",
        "\n",
        "## Experimental Design\n",
        "\n",
        "| Config        | IQ | Constellation | Spectrogram |\n",
        "|---------------|----|---------------|-------------|\n",
        "| IQ only       | ✓  |               |             |\n",
        "| Const only    |    | ✓             |             |\n",
        "| Spec only     |    |               | ✓           |\n",
        "| IQ + Const    | ✓  | ✓             |             |\n",
        "| IQ + Spec     | ✓  |               | ✓           |\n",
        "| Const + Spec  |    | ✓             | ✓           |\n",
        "| Full Fusion   | ✓  | ✓             | ✓           |\n",
        "\n",
        "Each configuration is trained **3 times with different random seeds**.  \n",
        "Results are reported as **mean ± std** overall accuracy.  \n",
        "Learning curves, saved model checkpoints, and per-SNR analysis are produced for every configuration."
      ],
      "metadata": {
        "id": "uaDvX-ldPwai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Install & Import Dependencies"
      ],
      "metadata": {
        "id": "2-txwRaSQmlp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AY1zpFfPUo4",
        "outputId": "751a13ac-372b-4aa8-c12a-786a81ad3314"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Models will be saved to: /content/saved_models/\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision numpy matplotlib scikit-learn tqdm scipy -q\n",
        "\n",
        "import os, time, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from scipy.signal import spectrogram as scipy_spectrogram\n",
        "from scipy.ndimage import zoom\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# ── Directory for saved models ────────────────────────────────────────────────\n",
        "SAVE_DIR = \"saved_models\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "print(f\"Models will be saved to: {os.path.abspath(SAVE_DIR)}/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Signal Generation & Dataset"
      ],
      "metadata": {
        "id": "WT7hiCTwR4Le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_awgn(signal, snr_db):\n",
        "    snr_lin = 10 ** (snr_db / 10.0)\n",
        "    pwr     = np.mean(np.abs(signal) ** 2)\n",
        "    noise   = np.sqrt(pwr / snr_lin / 2) * (\n",
        "        np.random.randn(*signal.shape) + 1j * np.random.randn(*signal.shape))\n",
        "    return signal + noise\n",
        "\n",
        "def gen_bpsk(n):   return np.random.choice([-1, 1], n).astype(complex)\n",
        "def gen_qpsk(n):   r=np.random.choice([-1,1],n); i=np.random.choice([-1,1],n); return (r+1j*i)/np.sqrt(2)\n",
        "def gen_8psk(n):   return np.exp(1j * np.random.randint(0,8,n) * np.pi/4)\n",
        "def gen_16qam(n):  v=np.array([-3,-1,1,3]); return (np.random.choice(v,n)+1j*np.random.choice(v,n))/np.sqrt(10)\n",
        "def gen_64qam(n):  v=np.array([-7,-5,-3,-1,1,3,5,7]); return (np.random.choice(v,n)+1j*np.random.choice(v,n))/np.sqrt(42)\n",
        "\n",
        "MODULATIONS = {\"BPSK\": gen_bpsk, \"QPSK\": gen_qpsk, \"8PSK\": gen_8psk,\n",
        "               \"16QAM\": gen_16qam, \"64QAM\": gen_64qam}\n",
        "MOD_NAMES = list(MODULATIONS.keys())\n",
        "\n",
        "def generate_dataset(samples_per_mod_snr=500, num_symbols=128,\n",
        "                     snrs=list(range(-20, 22, 2))):\n",
        "    X, y, snr_arr = [], [], []\n",
        "    for label, (name, func) in enumerate(MODULATIONS.items()):\n",
        "        for snr in snrs:\n",
        "            for _ in range(samples_per_mod_snr):\n",
        "                noisy = add_awgn(func(num_symbols), snr)\n",
        "                X.append(np.stack([np.real(noisy), np.imag(noisy)], axis=0))\n",
        "                y.append(label); snr_arr.append(snr)\n",
        "    return (np.array(X, dtype=np.float32),\n",
        "            np.array(y, dtype=np.int64),\n",
        "            np.array(snr_arr))\n",
        "\n",
        "SAMPLES_PER_MOD_SNR = 500\n",
        "NUM_SYMBOLS         = 128\n",
        "SNRs                = list(range(-20, 22, 2))\n",
        "\n",
        "print(\"Generating dataset …\")\n",
        "X, y, snr_vals = generate_dataset(SAMPLES_PER_MOD_SNR, NUM_SYMBOLS, SNRs)\n",
        "print(f\"  Shape  : {X.shape}\")\n",
        "print(f\"  Total  : {len(X):,} samples\")\n",
        "print(f\"  SNR    : {SNRs[0]} → {SNRs[-1]} dB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-Cf7bIsR5h-",
        "outputId": "93c377cd-4137-432c-cb4f-374cce62537b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating dataset …\n",
            "  Shape  : (52500, 2, 128)\n",
            "  Total  : 52,500 samples\n",
            "  SNR    : -20 → 20 dB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Image Generation & Dataset Class"
      ],
      "metadata": {
        "id": "6GaRsI5CSHAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 64\n",
        "\n",
        "def iq_to_constellation(iq, img_size=IMG_SIZE):\n",
        "    i, q = iq[0].numpy(), iq[1].numpy()\n",
        "    hist, _, _ = np.histogram2d(i, q, bins=img_size, range=[[-2,2],[-2,2]])\n",
        "    hist = hist.astype(np.float32)\n",
        "    if hist.max() > 0: hist /= hist.max()\n",
        "    return torch.from_numpy(np.stack([hist, hist, hist]))\n",
        "\n",
        "def iq_to_spectrogram(iq, img_size=IMG_SIZE, nperseg=64, noverlap=32):\n",
        "    cx = iq[0].numpy() + 1j * iq[1].numpy()\n",
        "    _, _, Sxx = scipy_spectrogram(cx, fs=1.0, nperseg=nperseg,\n",
        "                                  noverlap=noverlap, mode=\"magnitude\")\n",
        "    Sxx_db   = 10 * np.log10(np.abs(Sxx) + 1e-10)\n",
        "    Sxx_norm = (Sxx_db - Sxx_db.min()) / (Sxx_db.max() - Sxx_db.min() + 1e-8)\n",
        "    zf       = (img_size / Sxx_norm.shape[0], img_size / Sxx_norm.shape[1])\n",
        "    resized  = zoom(Sxx_norm.astype(np.float32), zf, order=1)\n",
        "    return torch.from_numpy(np.stack([resized, resized, resized]))\n",
        "\n",
        "\n",
        "class MultiModalDataset(Dataset):\n",
        "    def __init__(self, iq_tensors, labels):\n",
        "        self.iq     = iq_tensors\n",
        "        self.labels = torch.as_tensor(labels, dtype=torch.long)\n",
        "        print(\"  Pre-computing images …\")\n",
        "        consts, specs = [], []\n",
        "        for i in tqdm(range(len(iq_tensors))):\n",
        "            iq = iq_tensors[i]\n",
        "            consts.append(iq_to_constellation(iq))\n",
        "            specs.append(iq_to_spectrogram(iq))\n",
        "        self.const_imgs = torch.stack(consts)\n",
        "        self.spec_imgs  = torch.stack(specs)\n",
        "\n",
        "    def __len__(self): return len(self.iq)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.iq[idx], self.const_imgs[idx],\n",
        "                self.spec_imgs[idx], self.labels[idx])\n"
      ],
      "metadata": {
        "id": "l5uzlDAgSIvz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test, snr_train, snr_test = train_test_split(\n",
        "    X, y, snr_vals, test_size=0.3, random_state=42, stratify=y)\n",
        "\n",
        "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
        "X_test_t  = torch.tensor(X_test,  dtype=torch.float32)\n",
        "\n",
        "print(\"Building train dataset …\")\n",
        "train_ds = MultiModalDataset(X_train_t, y_train)\n",
        "print(\"\\nBuilding test dataset …\")\n",
        "test_ds  = MultiModalDataset(X_test_t,  y_test)\n",
        "print(f\"\\nTrain : {len(train_ds):,}  |  Test : {len(test_ds):,}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "d1fa1ca4eec84785bc5ed1ea2b12c6d3",
            "642ce2962a824c798649f9741c211665",
            "8424851db51d451b981bce7adea04844",
            "7a298c2789ef45a6a1e8da3e517cfc1c",
            "992d2604fdb64a5dbd39ac0210e1bfb8",
            "783a721bb3cd42f39c82914acf05e1b1",
            "f6a42519cc2a44a78b6a7a02340938d2",
            "f750bdd45778415ca9dff3727cdb7f48",
            "b762ad75bfa1405cb2fc2bbe0e089ace",
            "04884e6f206641a99769dc023668e023",
            "edfb3b37cc85481ebddb6d01d48e4557",
            "27735d0a59f74b159507f0fd8148fbd1",
            "19042770d05547ad961af1a73cbfd6a5",
            "a527b67c478f4b4b9b327990f30a2590",
            "e9f21c05f4f841aca084e29c46802e51",
            "c810e589d4f54f6bb4c692552f26d9dc",
            "06ba0ea5aa8b4fe586faf8b85515d87e",
            "b532917f9e734f6192107a5eb7846b8a",
            "7bd2c228eac6422794dbd89158b1c5b8",
            "707f580909104ce5a2da0682a1d3a949",
            "6765e38dc1a64470bba4bee9baaeb975",
            "9f52ddcbda044562b3eb2531593d829b"
          ]
        },
        "id": "tC6ukdXxSPPp",
        "outputId": "81e536af-d4a8-4a34-c2ee-0e400d8ed965"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building train dataset …\n",
            "  Pre-computing images …\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/36750 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1fa1ca4eec84785bc5ed1ea2b12c6d3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-416/3736878390.py:12: UserWarning: Input data is complex, switching to return_onesided=False\n",
            "  _, _, Sxx = scipy_spectrogram(cx, fs=1.0, nperseg=nperseg,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Building test dataset …\n",
            "  Pre-computing images …\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/15750 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27735d0a59f74b159507f0fd8148fbd1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Train : 36,750  |  Test : 15,750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Model Architecture"
      ],
      "metadata": {
        "id": "Zhh0uAaESQe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IQEncoder(nn.Module):\n",
        "    def __init__(self, out_dim=128):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv1d(2,   64,  3, padding=1), nn.BatchNorm1d(64),  nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(64,  128, 3, padding=1), nn.BatchNorm1d(128), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.Conv1d(128, 256, 3, padding=1), nn.BatchNorm1d(256), nn.ReLU(), nn.MaxPool1d(2),\n",
        "            nn.AdaptiveAvgPool1d(1))\n",
        "        self.fc = nn.Linear(256, out_dim)\n",
        "    def forward(self, x): return self.fc(self.net(x).squeeze(-1))\n",
        "\n",
        "\n",
        "class ImageEncoder(nn.Module):\n",
        "    def __init__(self, out_dim=128):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3,  32,  3, padding=1), nn.BatchNorm2d(32),  nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64,  3, padding=1), nn.BatchNorm2d(64),  nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.AdaptiveAvgPool2d(1))\n",
        "        self.fc = nn.Linear(128, out_dim)\n",
        "    def forward(self, x): return self.fc(self.net(x).squeeze(-1).squeeze(-1))\n",
        "\n",
        "\n",
        "class FusionModel(nn.Module):\n",
        "    \"\"\"\n",
        "    Flexible fusion model.\n",
        "    Active branches are controlled by use_iq / use_const / use_spec.\n",
        "    The fusion head input dimension adjusts automatically.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_classes=5, feat_dim=128,\n",
        "                 use_iq=True, use_const=True, use_spec=True):\n",
        "        super().__init__()\n",
        "        assert any([use_iq, use_const, use_spec]), \"At least one branch required.\"\n",
        "        self.use_iq = use_iq; self.use_const = use_const; self.use_spec = use_spec\n",
        "\n",
        "        if use_iq:    self.iq_enc    = IQEncoder(out_dim=feat_dim)\n",
        "        if use_const: self.const_enc = ImageEncoder(out_dim=feat_dim)\n",
        "        if use_spec:  self.spec_enc  = ImageEncoder(out_dim=feat_dim)\n",
        "\n",
        "        n = sum([use_iq, use_const, use_spec])\n",
        "        self.fusion = nn.Sequential(\n",
        "            nn.Linear(feat_dim * n, 256), nn.ReLU(), nn.Dropout(0.5),\n",
        "            nn.Linear(256, num_classes))\n",
        "\n",
        "    def forward(self, iq, const, spec):\n",
        "        feats = []\n",
        "        if self.use_iq:    feats.append(self.iq_enc(iq))\n",
        "        if self.use_const: feats.append(self.const_enc(const))\n",
        "        if self.use_spec:  feats.append(self.spec_enc(spec))\n",
        "        return self.fusion(torch.cat(feats, dim=1))"
      ],
      "metadata": {
        "id": "4uV-XRyrSdFk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Training & Evaluation Helpers"
      ],
      "metadata": {
        "id": "yuC6FqQaSilb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS  = 100\n",
        "BATCH_SIZE  = 256\n",
        "NUM_RUNS    = 3\n",
        "SEEDS       = list(range(NUM_RUNS))\n",
        "LR          = 1e-3\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=0)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "# Master results store — populated by each config cell below\n",
        "results = {}\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "def train_one_run(model, train_loader, test_loader, num_epochs, lr, snr_array):\n",
        "    \"\"\"\n",
        "    Train model for num_epochs.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    train_losses : list[float]   – per-epoch avg training loss\n",
        "    val_accs     : list[float]   – per-epoch test accuracy\n",
        "    best_state   : dict          – state_dict at best validation accuracy\n",
        "    snr_acc      : dict          – {snr: acc} at the best epoch\n",
        "    \"\"\"\n",
        "    opt  = optim.Adam(model.parameters(), lr=lr)\n",
        "    sched = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        opt, mode=\"max\", patience=7, factor=0.5, verbose=False)\n",
        "    crit = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_losses, val_accs = [], []\n",
        "    best_acc, best_state, best_snr_acc = 0.0, None, {}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        # ── Train ──────────────────────────────────────────────────────────\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for iq, const, spec, by in train_loader:\n",
        "            iq, const, spec, by = (iq.to(device), const.to(device),\n",
        "                                   spec.to(device), by.to(device))\n",
        "            opt.zero_grad()\n",
        "            loss = crit(model(iq, const, spec), by)\n",
        "            loss.backward(); opt.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_loss = total_loss / len(train_loader)\n",
        "        train_losses.append(avg_loss)\n",
        "\n",
        "        # ── Validate ───────────────────────────────────────────────────────\n",
        "        model.eval()\n",
        "        preds, labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for iq, const, spec, by in test_loader:\n",
        "                iq, const, spec = iq.to(device), const.to(device), spec.to(device)\n",
        "                preds.extend(model(iq, const, spec).argmax(1).cpu().numpy())\n",
        "                labels.extend(by.numpy())\n",
        "        preds, labels = np.array(preds), np.array(labels)\n",
        "        acc = accuracy_score(labels, preds)\n",
        "        val_accs.append(acc)\n",
        "        sched.step(acc)\n",
        "\n",
        "        # ── Track best ─────────────────────────────────────────────────────\n",
        "        if acc > best_acc:\n",
        "            best_acc   = acc\n",
        "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
        "            best_snr_acc = {}\n",
        "            for snr in np.unique(snr_array):\n",
        "                idx = np.where(snr_array == snr)[0]\n",
        "                best_snr_acc[snr] = accuracy_score(labels[idx], preds[idx])\n",
        "\n",
        "    return train_losses, val_accs, best_state, best_snr_acc\n",
        "\n",
        "def plot_learning_curves(cfg_name, all_train_losses, all_val_accs):\n",
        "    \"\"\"Plot loss + accuracy learning curves for all runs of one configuration.\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
        "    palette = [\"#e15759\", \"#4e79a7\", \"#59a14f\"]\n",
        "\n",
        "    for run_i, (losses, accs) in enumerate(zip(all_train_losses, all_val_accs)):\n",
        "        epochs = range(1, len(losses) + 1)\n",
        "        axes[0].plot(epochs, losses, color=palette[run_i],\n",
        "                     label=f\"Seed {run_i}\", linewidth=1.5)\n",
        "        axes[1].plot(epochs, [a * 100 for a in accs], color=palette[run_i],\n",
        "                     label=f\"Seed {run_i}\", linewidth=1.5)\n",
        "\n",
        "    for ax in axes:\n",
        "        ax.set_xlabel(\"Epoch\"); ax.legend(fontsize=8.5); ax.grid(True, alpha=0.4)\n",
        "    axes[0].set_ylabel(\"Cross-Entropy Loss\")\n",
        "    axes[0].set_title(f\"{cfg_name} — Training Loss\")\n",
        "    axes[1].set_ylabel(\"Test Accuracy (%)\")\n",
        "    axes[1].set_title(f\"{cfg_name} — Validation Accuracy\")\n",
        "\n",
        "    plt.suptitle(f\"Learning Curves: {cfg_name}\", fontsize=12, y=1.01)\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "\n",
        "def run_config(cfg_name, use_iq, use_const, use_spec):\n",
        "    \"\"\"\n",
        "    Train NUM_RUNS seeds for a single configuration.\n",
        "    Saves the best checkpoint of each run.\n",
        "    Populates results[cfg_name].\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*62}\")\n",
        "    print(f\"  Config : {cfg_name}\")\n",
        "    print(f\"  Active : IQ={use_iq}  Const={use_const}  Spec={use_spec}\")\n",
        "    print(f\"{'='*62}\")\n",
        "\n",
        "    all_train_losses, all_val_accs, all_best_accs, all_snr_accs = [], [], [], []\n",
        "\n",
        "    for seed in SEEDS:\n",
        "        print(f\"\\n  ── Run {seed+1}/{NUM_RUNS}  (seed={seed}) ──\")\n",
        "        set_seed(seed)\n",
        "        model = FusionModel(num_classes=len(MOD_NAMES),\n",
        "                            use_iq=use_iq, use_const=use_const, use_spec=use_spec\n",
        "                            ).to(device)\n",
        "\n",
        "        t0 = time.time()\n",
        "        train_losses, val_accs, best_state, snr_acc = train_one_run(\n",
        "            model, train_loader, test_loader, NUM_EPOCHS, LR, snr_test)\n",
        "        elapsed = time.time() - t0\n",
        "\n",
        "        best_acc = max(val_accs)\n",
        "        all_train_losses.append(train_losses)\n",
        "        all_val_accs.append(val_accs)\n",
        "        all_best_accs.append(best_acc)\n",
        "        all_snr_accs.append(snr_acc)\n",
        "\n",
        "        # ── Save checkpoint ────────────────────────────────────────────────\n",
        "        safe_name = cfg_name.lower().replace(\" \", \"_\").replace(\"+\", \"plus\")\n",
        "        ckpt_path = os.path.join(SAVE_DIR, f\"{safe_name}_seed{seed}.pt\")\n",
        "        torch.save({\n",
        "            \"config\":      cfg_name,\n",
        "            \"use_iq\":      use_iq,\n",
        "            \"use_const\":   use_const,\n",
        "            \"use_spec\":    use_spec,\n",
        "            \"seed\":        seed,\n",
        "            \"best_acc\":    best_acc,\n",
        "            \"state_dict\":  best_state,\n",
        "            \"train_losses\": train_losses,\n",
        "            \"val_accs\":    val_accs,\n",
        "            \"snr_acc\":     snr_acc,\n",
        "        }, ckpt_path)\n",
        "\n",
        "        print(f\"     Best acc : {best_acc*100:.2f}%  |  Time: {elapsed:.0f}s\")\n",
        "        print(f\"     Saved  → {ckpt_path}\")\n",
        "\n",
        "    # ── Learning curves for this config ────────────────────────────────────\n",
        "    plot_learning_curves(cfg_name, all_train_losses, all_val_accs)\n",
        "\n",
        "    # ── Store in global results dict ───────────────────────────────────────\n",
        "    results[cfg_name] = {\n",
        "        \"accs\":      all_best_accs,\n",
        "        \"snr_accs\":  all_snr_accs,\n",
        "    }\n",
        "\n",
        "    mean_acc, std_acc = np.mean(all_best_accs) * 100, np.std(all_best_accs) * 100\n",
        "    print(f\"\\n  Summary  →  {mean_acc:.2f}% ± {std_acc:.2f}%\")\n",
        "    return results[cfg_name]\n",
        "\n"
      ],
      "metadata": {
        "id": "kXbus-J-SkLR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6. Run Each Configuration\n",
        "Each cell below is fully self-contained — you can re-run any single configuration independently without re-running the others.\n",
        "\n",
        "#6.1 — IQ only\n",
        "Active branches: IQ"
      ],
      "metadata": {
        "id": "EsHR6a4GTS5i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_config(\"IQ only\", use_iq=True, use_const=False, use_spec=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "wupif734TeQr",
        "outputId": "ece0415c-8a44-4ddb-a533-2caadd103a40"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==============================================================\n",
            "  Config : IQ only\n",
            "  Active : IQ=True  Const=False  Spec=False\n",
            "==============================================================\n",
            "\n",
            "  ── Run 1/3  (seed=0) ──\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-416/1360650135.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IQ only\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_iq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_const\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-416/584208312.py\u001b[0m in \u001b[0;36mrun_config\u001b[0;34m(cfg_name, use_iq, use_const, use_spec)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         train_losses, val_accs, best_state, snr_acc = train_one_run(\n\u001b[0m\u001b[1;32m    122\u001b[0m             model, train_loader, test_loader, NUM_EPOCHS, LR, snr_test)\n\u001b[1;32m    123\u001b[0m         \u001b[0melapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-416/584208312.py\u001b[0m in \u001b[0;36mtrain_one_run\u001b[0;34m(model, train_loader, test_loader, num_epochs, lr, snr_array)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \"\"\"\n\u001b[1;32m     31\u001b[0m     \u001b[0mopt\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     sched = optim.lr_scheduler.ReduceLROnPlateau(\n\u001b[0m\u001b[1;32m     33\u001b[0m         opt, mode=\"max\", patience=7, factor=0.5, verbose=False)\n\u001b[1;32m     34\u001b[0m     \u001b[0mcrit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ReduceLROnPlateau.__init__() got an unexpected keyword argument 'verbose'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.2 — Const only\n",
        "Active branches: Constellation"
      ],
      "metadata": {
        "id": "RcmBhZCLThVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_config(\"Const only\", use_iq=False, use_const=True, use_spec=False)"
      ],
      "metadata": {
        "id": "to6xMm75Tw-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.3 — Spec only\n",
        "Active branches: Spectrogram"
      ],
      "metadata": {
        "id": "zPXvBBDXcTYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_config(\"Spec only\", use_iq=False, use_const=False, use_spec=True)"
      ],
      "metadata": {
        "id": "hHBECh_McWQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.4 — IQ + Const\n",
        "Active branches: IQ + Constellation"
      ],
      "metadata": {
        "id": "8_Ey-ILZcZ8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_config(\"IQ + Const\", use_iq=True, use_const=True, use_spec=False)"
      ],
      "metadata": {
        "id": "eQYIkIq4cb6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.5 — IQ + Spec\n",
        "Active branches: IQ + Spectrogram"
      ],
      "metadata": {
        "id": "vydG5QAccfiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_config(\"IQ + Spec\", use_iq=True, use_const=False, use_spec=True)"
      ],
      "metadata": {
        "id": "iuLurGWfeLgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.6 — Const + Spec\n",
        "Active branches: Constellation + Spectrogram"
      ],
      "metadata": {
        "id": "41Zv80s3eNGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_config(\"Const + Spec\", use_iq=False, use_const=True, use_spec=True)"
      ],
      "metadata": {
        "id": "OwX-lQ54eQDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##6.7 — Full Fusion\n",
        "Active branches: IQ + Constellation + Spectrogram"
      ],
      "metadata": {
        "id": "6iwAT_JceUrC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run_config(\"Full Fusion\", use_iq=True, use_const=True, use_spec=True)"
      ],
      "metadata": {
        "id": "CJbLw-yheYGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##7. Aggregate Results\n",
        "Run this section only after all 7 configuration cells above have completed."
      ],
      "metadata": {
        "id": "7A8uYk77exxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Summary table ─────────────────────────────────────────────────────────────\n",
        "cfg_names = [c[0] for c in [\n",
        "    (\"IQ only\",      True,  False, False),\n",
        "    (\"Const only\",   False, True,  False),\n",
        "    (\"Spec only\",    False, False, True),\n",
        "    (\"IQ + Const\",   True,  True,  False),\n",
        "    (\"IQ + Spec\",    True,  False, True),\n",
        "    (\"Const + Spec\", False, True,  True),\n",
        "    (\"Full Fusion\",  True,  True,  True),\n",
        "]]\n",
        "\n",
        "print(f\"{'Configuration':<18}  {'Mean Acc':>9}  {'Std':>7}  {'Min':>7}  {'Max':>7}\")\n",
        "print(\"-\" * 55)\n",
        "summary = {}\n",
        "for name in cfg_names:\n",
        "    if name not in results:\n",
        "        print(f\"{name:<18}  (not run yet)\"); continue\n",
        "    accs = results[name][\"accs\"]\n",
        "    mean, std = np.mean(accs) * 100, np.std(accs) * 100\n",
        "    summary[name] = (mean, std)\n",
        "    print(f\"{name:<18}  {mean:>8.2f}%  {std:>6.2f}%  \"\n",
        "          f\"{min(accs)*100:>6.2f}%  {max(accs)*100:>6.2f}%\")"
      ],
      "metadata": {
        "id": "6LEiK62ke04Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Bar chart ─────────────────────────────────────────────────────────────────\n",
        "names  = [n for n in cfg_names if n in summary]\n",
        "means  = [summary[n][0] for n in names]\n",
        "stds   = [summary[n][1] for n in names]\n",
        "colours = [\"#7f7f7f\"]*3 + [\"#4e8ecb\"]*3 + [\"#e8a838\"]\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(11, 5))\n",
        "bars = ax.bar(names, means, yerr=stds, capsize=5,\n",
        "              color=colours, edgecolor=\"black\", linewidth=0.6,\n",
        "              width=0.55, error_kw=dict(elinewidth=1.5, ecolor=\"black\"))\n",
        "\n",
        "for bar, m, s in zip(bars, means, stds):\n",
        "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + s + 0.3,\n",
        "            f\"{m:.1f}%\", ha=\"center\", va=\"bottom\", fontsize=8.5, fontweight=\"bold\")\n",
        "\n",
        "ax.set_ylabel(\"Test Accuracy (%)\", fontsize=11)\n",
        "ax.set_title(f\"Ablation Study — Mean ± Std Accuracy ({NUM_RUNS} runs each)\", fontsize=12)\n",
        "ax.set_ylim(0, min(105, max(means) + max(stds) + 8))\n",
        "ax.grid(axis=\"y\", linestyle=\"--\", alpha=0.5)\n",
        "ax.set_xticklabels(names, rotation=15, ha=\"right\")\n",
        "\n",
        "from matplotlib.patches import Patch\n",
        "ax.legend(handles=[\n",
        "    Patch(facecolor=\"#7f7f7f\", edgecolor=\"black\", label=\"Single branch\"),\n",
        "    Patch(facecolor=\"#4e8ecb\", edgecolor=\"black\", label=\"Two branches\"),\n",
        "    Patch(facecolor=\"#e8a838\", edgecolor=\"black\", label=\"Full fusion\"),\n",
        "], loc=\"lower right\")\n",
        "\n",
        "plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "chL69ZHLe34P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Per-SNR accuracy curves ────────────────────────────────────────────────────\n",
        "snrs_unique = sorted(np.unique(snr_test))\n",
        "palette     = plt.cm.tab10(np.linspace(0, 1, len(cfg_names)))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(11, 6))\n",
        "for name, colour in zip(cfg_names, palette):\n",
        "    if name not in results: continue\n",
        "    runs      = results[name][\"snr_accs\"]\n",
        "    mean_c    = np.array([np.mean([r[s] for r in runs]) for s in snrs_unique])\n",
        "    std_c     = np.array([np.std( [r[s] for r in runs]) for s in snrs_unique])\n",
        "    ls        = \"-\" if \"IQ\" in name else \"--\"\n",
        "    ax.plot(snrs_unique, mean_c*100, label=name, color=colour,\n",
        "            linewidth=2, linestyle=ls, marker=\"o\", markersize=4)\n",
        "    ax.fill_between(snrs_unique, (mean_c-std_c)*100, (mean_c+std_c)*100,\n",
        "                    alpha=0.12, color=colour)\n",
        "\n",
        "ax.axhline(20, color=\"black\", linestyle=\":\", linewidth=1, alpha=0.5, label=\"Random (20%)\")\n",
        "ax.set_xlabel(\"SNR (dB)\", fontsize=11); ax.set_ylabel(\"Accuracy (%)\", fontsize=11)\n",
        "ax.set_title(f\"Per-SNR Accuracy — All Configurations\\n(shaded = ±1 std, {NUM_RUNS} runs)\",\n",
        "             fontsize=12)\n",
        "ax.legend(loc=\"upper left\", fontsize=8.5, ncol=2)\n",
        "ax.grid(True, linestyle=\"--\", alpha=0.4)\n",
        "ax.set_xticks(snrs_unique)\n",
        "plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "cRsEc4H5fN1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ── Heat-map ──────────────────────────────────────────────────────────────────\n",
        "snrs_unique  = sorted(np.unique(snr_test))\n",
        "active_names = [n for n in cfg_names if n in results]\n",
        "\n",
        "heatmap = np.zeros((len(active_names), len(snrs_unique)))\n",
        "for ci, name in enumerate(active_names):\n",
        "    for si, snr in enumerate(snrs_unique):\n",
        "        heatmap[ci, si] = np.mean([r[snr] for r in results[name][\"snr_accs\"]])\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(14, 4))\n",
        "im = ax.imshow(heatmap * 100, aspect=\"auto\", cmap=\"RdYlGn\", vmin=0, vmax=100)\n",
        "fig.colorbar(im, ax=ax, pad=0.02).set_label(\"Accuracy (%)\")\n",
        "ax.set_xticks(range(len(snrs_unique))); ax.set_xticklabels(snrs_unique, fontsize=8)\n",
        "ax.set_yticks(range(len(active_names))); ax.set_yticklabels(active_names, fontsize=9)\n",
        "ax.set_xlabel(\"SNR (dB)\"); ax.set_title(\"Mean Accuracy Heat-map per Configuration & SNR\")\n",
        "\n",
        "for ci in range(len(active_names)):\n",
        "    for si in range(len(snrs_unique)):\n",
        "        v = heatmap[ci, si] * 100\n",
        "        ax.text(si, ci, f\"{v:.0f}\", ha=\"center\", va=\"center\",\n",
        "                fontsize=6.5, color=\"black\" if 20 < v < 80 else \"white\")\n",
        "plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "TqNRjKq9fQf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##8. Statistical Significance Testing"
      ],
      "metadata": {
        "id": "GA9OWMFgfb9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "baseline = \"Full Fusion\"\n",
        "if baseline in results:\n",
        "    base_accs = results[baseline][\"accs\"]\n",
        "    print(f\"Pairwise t-tests vs '{baseline}'  (two-sided, α = 0.05)\\n\")\n",
        "    print(f\"{'Config':<18}  {'Δ Acc':>8}  {'p-value':>10}  {'Sig?':>6}\")\n",
        "    print(\"-\" * 48)\n",
        "    for name in cfg_names:\n",
        "        if name == baseline or name not in results: continue\n",
        "        _, p     = ttest_ind(base_accs, results[name][\"accs\"])\n",
        "        delta    = (np.mean(base_accs) - np.mean(results[name][\"accs\"])) * 100\n",
        "        print(f\"{name:<18}  {delta:>+7.2f}%  {p:>10.4f}  {'YES ✓' if p < 0.05 else 'no':>6}\")\n",
        "    print(\"\\nNote: increase NUM_RUNS to ≥5 for publication-quality significance.\")\n",
        "else:\n",
        "    print(\"Full Fusion results not available yet — run all config cells first.\")"
      ],
      "metadata": {
        "id": "3cB4JJ5bffmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##9. Load Saved Models\n",
        "Use the cell below to reload any checkpoint — useful for resuming analysis or running inference without retraining."
      ],
      "metadata": {
        "id": "t6wSYNqefjNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(cfg_name, seed):\n",
        "    \"\"\"\n",
        "    Reload a saved checkpoint and return a ready-to-use model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    cfg_name : str   e.g. \"Full Fusion\"\n",
        "    seed     : int   0, 1, or 2\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    model : FusionModel   loaded on `device`, set to eval mode\n",
        "    ckpt  : dict          full checkpoint dict (includes curves, snr_acc, etc.)\n",
        "    \"\"\"\n",
        "    safe_name = cfg_name.lower().replace(\" \", \"_\").replace(\"+\", \"plus\")\n",
        "    path      = os.path.join(SAVE_DIR, f\"{safe_name}_seed{seed}.pt\")\n",
        "    ckpt      = torch.load(path, map_location=device)\n",
        "\n",
        "    model = FusionModel(\n",
        "        num_classes=len(MOD_NAMES),\n",
        "        use_iq=ckpt[\"use_iq\"],\n",
        "        use_const=ckpt[\"use_const\"],\n",
        "        use_spec=ckpt[\"use_spec\"],\n",
        "    ).to(device)\n",
        "    model.load_state_dict(ckpt[\"state_dict\"])\n",
        "    model.eval()\n",
        "\n",
        "    print(f\"Loaded  : {path}\")\n",
        "    print(f\"Config  : {ckpt['config']}  |  Seed: {ckpt['seed']}\")\n",
        "    print(f\"Best acc: {ckpt['best_acc']*100:.2f}%\")\n",
        "    return model, ckpt\n",
        "\n",
        "\n",
        "# ── Example usage ─────────────────────────────────────────────────────────────\n",
        "# model, ckpt = load_checkpoint(\"Full Fusion\", seed=0)\n",
        "#\n",
        "# Replay the learning curves from the saved data:\n",
        "# plot_learning_curves(ckpt[\"config\"], [ckpt[\"train_losses\"]], [ckpt[\"val_accs\"]])\n",
        "\n",
        "print(\"load_checkpoint() is ready.  Uncomment the example lines above to use it.\")\n",
        "print(\"\\nSaved checkpoints:\")\n",
        "for f in sorted(os.listdir(SAVE_DIR)):\n",
        "    path = os.path.join(SAVE_DIR, f)\n",
        "    print(f\"  {f}  ({os.path.getsize(path)/1024:.0f} KB)\")"
      ],
      "metadata": {
        "id": "XUD0D90EfmQC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}